{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/626170998/tonyff/blob/main/lama_cleaner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lk9wAWLScQ1R",
        "outputId": "18137423-16f3-46fd-faf2-dddbf867b3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lama-cleaner\n",
            "  Downloading lama_cleaner-1.2.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.0.0.tar.gz (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.7/718.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from lama-cleaner) (2.0.1+cu118)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from lama-cleaner) (4.8.0.76)\n",
            "Collecting flask==2.2.3 (from lama-cleaner)\n",
            "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask-socketio (from lama-cleaner)\n",
            "  Downloading Flask_SocketIO-5.3.6-py3-none-any.whl (18 kB)\n",
            "Collecting simple-websocket (from lama-cleaner)\n",
            "  Downloading simple_websocket-0.10.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting flask-cors (from lama-cleaner)\n",
            "  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Collecting flaskwebgui==0.3.5 (from lama-cleaner)\n",
            "  Downloading flaskwebgui-0.3.5-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from lama-cleaner) (1.10.13)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from lama-cleaner) (13.5.3)\n",
            "Collecting loguru (from lama-cleaner)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs (from lama-cleaner)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting diffusers==0.16.1 (from lama-cleaner)\n",
            "  Downloading diffusers-0.16.1-py3-none-any.whl (934 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.9/934.9 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.27.4 (from lama-cleaner)\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from lama-cleaner)\n",
            "  Downloading gradio-3.46.1-py3-none-any.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting piexif==1.1.3 (from lama-cleaner)\n",
            "  Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting safetensors (from lama-cleaner)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf (from lama-cleaner)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting controlnet-aux==0.0.3 (from lama-cleaner)\n",
            "  Downloading controlnet_aux-0.0.3-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (9.4.0)\n",
            "Collecting einops (from controlnet-aux==0.0.3->lama-cleaner)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (3.12.4)\n",
            "Collecting huggingface-hub (from controlnet-aux==0.0.3->lama-cleaner)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (6.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (1.23.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (1.11.3)\n",
            "Collecting timm (from controlnet-aux==0.0.3->lama-cleaner)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.3->lama-cleaner) (0.15.2+cu118)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1->lama-cleaner) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1->lama-cleaner) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask==2.2.3->lama-cleaner) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.2.3->lama-cleaner) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.2.3->lama-cleaner) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.2.3->lama-cleaner) (8.1.7)\n",
            "Collecting whichcraft (from flaskwebgui==0.3.5->lama-cleaner)\n",
            "  Downloading whichcraft-0.6.1-py2.py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->lama-cleaner) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->lama-cleaner) (6.0.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4->lama-cleaner)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->lama-cleaner) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->lama-cleaner) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->lama-cleaner) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->lama-cleaner) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->lama-cleaner) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->lama-cleaner) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->lama-cleaner) (17.0.1)\n",
            "Collecting python-socketio>=5.0.2 (from flask-socketio->lama-cleaner)\n",
            "  Downloading python_socketio-5.9.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->lama-cleaner)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->lama-cleaner) (4.2.2)\n",
            "Collecting fastapi (from gradio->lama-cleaner)\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->lama-cleaner)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.3 (from gradio->lama-cleaner)\n",
            "  Downloading gradio_client-0.5.3-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->lama-cleaner)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->lama-cleaner) (6.1.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->lama-cleaner) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->lama-cleaner) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->lama-cleaner)\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->lama-cleaner) (1.5.3)\n",
            "Collecting pydub (from gradio->lama-cleaner)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->lama-cleaner)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->lama-cleaner)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->lama-cleaner)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio->lama-cleaner)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.3->gradio->lama-cleaner) (2023.6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->lama-cleaner)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->lama-cleaner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->lama-cleaner) (2.16.1)\n",
            "Collecting wsproto (from simple-websocket->lama-cleaner)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->lama-cleaner) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->lama-cleaner) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->lama-cleaner) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->lama-cleaner) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->lama-cleaner) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->lama-cleaner) (2023.3.post1)\n",
            "Collecting bidict>=0.21.0 (from python-socketio>=5.0.2->flask-socketio->lama-cleaner)\n",
            "  Downloading bidict-0.22.1-py3-none-any.whl (35 kB)\n",
            "Collecting python-engineio>=4.7.0 (from python-socketio>=5.0.2->flask-socketio->lama-cleaner)\n",
            "  Downloading python_engineio-4.7.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.16.1->lama-cleaner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.16.1->lama-cleaner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.16.1->lama-cleaner) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.16.1->lama-cleaner) (2023.7.22)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->lama-cleaner)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->lama-cleaner) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->lama-cleaner)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->lama-cleaner)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m501.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->lama-cleaner) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->controlnet-aux==0.0.3->lama-cleaner) (3.17.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->controlnet-aux==0.0.3->lama-cleaner) (2.31.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->controlnet-aux==0.0.3->lama-cleaner) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->controlnet-aux==0.0.3->lama-cleaner) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->lama-cleaner) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->lama-cleaner) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->lama-cleaner) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->lama-cleaner) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->lama-cleaner) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->lama-cleaner) (0.10.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->lama-cleaner) (1.16.0)\n",
            "Building wheels for collected packages: pyngrok, antlr4-python3-runtime, ffmpy\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.0-py3-none-any.whl size=21129 sha256=02c1816d9ce7e5b6f2d2020531ea91f0bf824ec5268c457451def66c857d545a\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/29/7b/f64332aa7e5e88fbd56d4002185ae22dcdc83b35b3d1c2cbf5\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a2dd709282f03e44579808840a96503b2824a1675fd40d66a9c5e2226b10f9bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=5fc35e9b52d97dd2d241e2a939ca0a606eb121832e92efc26a1df615cdc3b5f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built pyngrok antlr4-python3-runtime ffmpy\n",
            "Installing collected packages: whichcraft, tokenizers, safetensors, pydub, ffmpy, antlr4-python3-runtime, yacs, websockets, semantic-version, python-multipart, pyngrok, piexif, orjson, omegaconf, loguru, h11, flaskwebgui, einops, bidict, aiofiles, wsproto, uvicorn, starlette, huggingface-hub, httpcore, flask, transformers, simple-websocket, httpx, flask-cors, fastapi, diffusers, python-engineio, gradio-client, python-socketio, gradio, flask-socketio, timm, controlnet-aux, lama-cleaner\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 2.2.5\n",
            "    Uninstalling Flask-2.2.5:\n",
            "      Successfully uninstalled Flask-2.2.5\n",
            "Successfully installed aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 bidict-0.22.1 controlnet-aux-0.0.3 diffusers-0.16.1 einops-0.7.0 fastapi-0.103.2 ffmpy-0.3.1 flask-2.2.3 flask-cors-4.0.0 flask-socketio-5.3.6 flaskwebgui-0.3.5 gradio-3.46.1 gradio-client-0.5.3 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 lama-cleaner-1.2.3 loguru-0.7.2 omegaconf-2.3.0 orjson-3.9.7 piexif-1.1.3 pydub-0.25.1 pyngrok-7.0.0 python-engineio-4.7.1 python-multipart-0.0.6 python-socketio-5.9.0 safetensors-0.3.3 semantic-version-2.10.0 simple-websocket-0.10.1 starlette-0.27.0 timm-0.9.7 tokenizers-0.13.3 transformers-4.27.4 uvicorn-0.23.2 websockets-11.0.3 whichcraft-0.6.1 wsproto-1.2.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title 1. Install package\n",
        "#@markdown # 1. Install package\n",
        "#@markdown Github Project: https://github.com/Sanster/lama-cleaner\n",
        "\n",
        "!pip3 install lama-cleaner pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download model\n",
        "#@markdown # 2. Downloading model\n",
        "init_model = 'lama' #@param ['lama', 'sd1.5', 'paint_by_example']\n",
        "port = 4242\n",
        "\n",
        "#@markdown # !! Important Notes !!\n",
        "#@markdown Please stop this block after model download finish (seeing `running on http://0.0.0.0:4242/` in the log)\n",
        "\n",
        "!lama-cleaner --host 0.0.0.0 --port $port --model $init_model"
      ],
      "metadata": {
        "id": "nF5-ak8F4Iem",
        "outputId": "158a8870-cfc1-4774-a52f-3082f67674b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Platform: Linux-\u001b[1;36m5.15\u001b[0m.\u001b[1;36m120\u001b[0m+-x86_64-with-glibc2.\u001b[1;36m35\u001b[0m\n",
            "- Python version: \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m\n",
            "- torch: \u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118\n",
            "- torchvision: \u001b[1;36m0.15\u001b[0m.\u001b[1;36m2\u001b[0m+cu118\n",
            "- Pillow: \u001b[1;36m9.4\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "- diffusers: \u001b[1;36m0.16\u001b[0m.\u001b[1;36m1\u001b[0m\n",
            "- transformers: \u001b[1;36m4.27\u001b[0m.\u001b[1;36m4\u001b[0m\n",
            "- opencv-python: \u001b[1;92m4.8.0.76\u001b[0m\n",
            "- xformers: N/A\n",
            "- accelerate: N/A\n",
            "- lama-cleaner: \u001b[1;36m1.2\u001b[0m.\u001b[1;36m3\u001b[0m\n",
            "- rembg: N/A\n",
            "- realesrgan: N/A\n",
            "- gfpgan: N/A\n",
            "\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2023-10-05 13:58:11.950930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: \"https://github.com/Sanster/models/releases/download/add_big_lama/big-lama.pt\" to /root/.cache/torch/hub/checkpoints/big-lama.pt\n",
            "100% 196M/196M [00:00<00:00, 220MB/s]\n",
            "\u001b[32m2023-10-05 13:58:15.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDownload model success, md5: e3aa4aaa15225a33ec84f9f4bc47e500\u001b[0m\n",
            "\u001b[32m2023-10-05 13:58:15.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mLoading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\u001b[0m\n",
            "Running on http://127.0.0.1:4242\n",
            " * Running on http://172.28.0.12:4242\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Setup ngrok\n",
        "\n",
        "#@markdown # 3. Setup ngrok\n",
        "#@markdown Get a free [ngrok](https://ngrok.com/) account and copy your authtoken [here](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "ngrok_authtoken = '2WLWjYd0JE3aCeO4HvZ5hmpWMYY_4nBQwcnb6LELrhrcdwGRX' #@param {type: 'string'}\n",
        "\n",
        "!ngrok authtoken $ngrok_authtoken\n",
        "\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"ngrok public url: {public_url}.\")"
      ],
      "metadata": {
        "id": "qKe0DDAUgGBw",
        "outputId": "afb0191f-46c3-4983-bc81-4ec7d5aa62b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-10-05T14:00:50+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok public url: https://e2f6-34-171-169-10.ngrok-free.app.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Start Lama Cleaner server\n",
        "#@markdown # 4. Start Lama Cleaner server\n",
        "#@markdown When you see `Running on http://0.0.0.0:4242/' in the log`, please open **ngrok public link**\n",
        "\n",
        "\n",
        "!lama-cleaner --host 0.0.0.0 --port $port --model $init_model"
      ],
      "metadata": {
        "id": "AlZ4devxcxCS",
        "outputId": "4901aad0-af36-4bd2-8ccc-d30bb4e4c984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Platform: Linux-\u001b[1;36m5.15\u001b[0m.\u001b[1;36m120\u001b[0m+-x86_64-with-glibc2.\u001b[1;36m35\u001b[0m\n",
            "- Python version: \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m\n",
            "- torch: \u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118\n",
            "- torchvision: \u001b[1;36m0.15\u001b[0m.\u001b[1;36m2\u001b[0m+cu118\n",
            "- Pillow: \u001b[1;36m9.4\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "- diffusers: \u001b[1;36m0.16\u001b[0m.\u001b[1;36m1\u001b[0m\n",
            "- transformers: \u001b[1;36m4.27\u001b[0m.\u001b[1;36m4\u001b[0m\n",
            "- opencv-python: \u001b[1;92m4.8.0.76\u001b[0m\n",
            "- xformers: N/A\n",
            "- accelerate: N/A\n",
            "- lama-cleaner: \u001b[1;36m1.2\u001b[0m.\u001b[1;36m3\u001b[0m\n",
            "- rembg: N/A\n",
            "- realesrgan: N/A\n",
            "- gfpgan: N/A\n",
            "\n",
            "2023-10-05 14:00:56.235781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2023-10-05 14:00:57.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mLoading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\u001b[0m\n",
            "Running on http://127.0.0.1:4242\n",
            " * Running on http://172.28.0.12:4242\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:01:55] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:01:55] \"GET /static/css/main.ce986cc8.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:01:55] \"GET /static/js/main.1fda6320.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:31] \"GET /is_desktop HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:31] \"GET /server_config HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:31] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:31] \"GET /static/media/Inter-roman.var.ba4caefcdf5b36b438db.woff2 HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:31] \"GET /inputimage HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:48] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:02:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:03:00] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:04:05.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1266, 1266, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:04:05.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-10-05 14:04:05.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mRun crop strategy\u001b[0m\n",
            "\u001b[32m2023-10-05 14:04:05.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_crop_box\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mbox size: (496,354) crop size: (888, 746, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:04:05.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (888, 752, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:04:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 8568.528413772583ms\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:04:13] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:04:24] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:04:44] \"GET /model_downloaded/realisticVision1.4 HTTP/1.1\" 200 -\n",
            "Downloading (…)p16/model_index.json: 100% 586/586 [00:00<00:00, 3.00MB/s]\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading (…)_checker/config.json: 100% 5.01k/5.01k [00:00<00:00, 27.3MB/s]\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 732/732 [00:00<00:00, 3.58MB/s]\n",
            "\n",
            "Downloading (…)rocessor_config.json: 100% 520/520 [00:00<00:00, 3.23MB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:10,  1.30it/s]\n",
            "Downloading (…)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.93MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 923/923 [00:00<00:00, 4.73MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 8.80MB/s]\n",
            "\n",
            "Downloading (…)f1a/unet/config.json: 100% 1.18k/1.18k [00:00<00:00, 4.45MB/s]\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 14.6MB/s]\n",
            "\n",
            "Downloading (…)7f1a/vae/config.json: 100% 711/711 [00:00<00:00, 4.36MB/s]\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 341/341 [00:00<00:00, 1.66MB/s]\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   4% 10.5M/246M [00:00<00:03, 74.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 10.5M/167M [00:00<00:01, 98.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 41.9M/167M [00:00<00:00, 204MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 73.4M/167M [00:00<00:00, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   2% 10.5M/608M [00:00<00:09, 63.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  13% 31.5M/246M [00:00<00:03, 56.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 105M/167M [00:00<00:00, 194MB/s] \u001b[A\u001b[A\n",
            "Downloading model.safetensors:  21% 52.4M/246M [00:00<00:02, 85.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 126M/167M [00:00<00:00, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 167M/167M [00:00<00:00, 203MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 10.5M/1.72G [00:00<01:53, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 21.0M/1.72G [00:00<00:56, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  30% 73.4M/246M [00:01<00:02, 65.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   5% 31.5M/608M [00:00<00:14, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   7% 41.9M/608M [00:00<00:13, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  38% 94.4M/246M [00:01<00:02, 68.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 31.5M/1.72G [00:01<01:03, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 41.9M/1.72G [00:01<00:46, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   9% 52.4M/608M [00:01<00:16, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  47% 115M/246M [00:01<00:02, 61.1MB/s] \u001b[A\n",
            "Downloading model.safetensors:  51% 126M/246M [00:02<00:02, 58.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 52.4M/1.72G [00:01<00:52, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  14% 83.9M/608M [00:01<00:09, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 62.9M/1.72G [00:01<00:44, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  60% 147M/246M [00:02<00:01, 56.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  17% 105M/608M [00:02<00:09, 50.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   5% 83.9M/1.72G [00:03<01:13, 22.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  19% 115M/608M [00:03<00:17, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  64% 157M/246M [00:03<00:03, 26.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  21% 126M/608M [00:03<00:14, 32.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  68% 168M/246M [00:03<00:02, 28.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   5% 94.4M/1.72G [00:03<01:07, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  24% 147M/608M [00:03<00:10, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  26% 157M/608M [00:03<00:08, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  77% 189M/246M [00:04<00:01, 40.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 199M/246M [00:04<00:01, 46.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  29% 178M/608M [00:03<00:06, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  85% 210M/246M [00:04<00:00, 52.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  31% 189M/608M [00:04<00:07, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 105M/1.72G [00:04<01:34, 17.1MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  94% 231M/246M [00:06<00:00, 19.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  33% 199M/608M [00:08<00:43, 9.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   7% 115M/1.72G [00:08<03:44, 7.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  98% 241M/246M [00:08<00:00, 11.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  34% 210M/608M [00:08<00:33, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors: 100% 246M/246M [00:08<00:00, 28.0MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   8% 136M/1.72G [00:08<02:00, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  36% 220M/608M [00:08<00:24, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 147M/1.72G [00:08<01:29, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  38% 231M/608M [00:08<00:18, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 157M/1.72G [00:08<01:08, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  40% 241M/608M [00:08<00:14, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  10% 168M/1.72G [00:08<00:52, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  41% 252M/608M [00:08<00:10, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  45% 273M/608M [00:09<00:07, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  11% 189M/1.72G [00:09<00:35, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  12% 210M/1.72G [00:12<02:03, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  48% 294M/608M [00:13<00:28, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 220M/1.72G [00:13<01:53, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 231M/1.72G [00:13<01:29, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  50% 304M/608M [00:13<00:22, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  14% 241M/1.72G [00:13<01:10, 20.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  15% 252M/1.72G [00:13<00:55, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  16% 273M/1.72G [00:13<00:34, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  52% 315M/608M [00:13<00:19, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  18% 304M/1.72G [00:13<00:20, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  55% 336M/608M [00:13<00:11, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 325M/1.72G [00:14<00:17, 81.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  59% 357M/608M [00:18<00:25, 9.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  20% 346M/1.72G [00:18<01:37, 14.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  62% 377M/608M [00:18<00:16, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  21% 367M/1.72G [00:18<01:11, 19.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  64% 388M/608M [00:18<00:12, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 377M/1.72G [00:18<01:01, 21.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  67% 409M/608M [00:18<00:08, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  23% 398M/1.72G [00:18<00:43, 30.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  71% 430M/608M [00:18<00:05, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  24% 409M/1.72G [00:19<00:38, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  74% 451M/608M [00:19<00:03, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 430M/1.72G [00:19<00:28, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  76% 461M/608M [00:19<00:02, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  26% 451M/1.72G [00:19<00:21, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  79% 482M/608M [00:19<00:01, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  27% 472M/1.72G [00:19<00:17, 73.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  83% 503M/608M [00:19<00:01, 75.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  29% 493M/1.72G [00:19<00:14, 84.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  86% 524M/608M [00:21<00:02, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  30% 514M/1.72G [00:21<00:38, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  90% 545M/608M [00:21<00:01, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  31% 535M/1.72G [00:21<00:28, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  32% 545M/1.72G [00:21<00:25, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  93% 566M/608M [00:21<00:00, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  33% 566M/1.72G [00:21<00:19, 58.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  97% 587M/608M [00:21<00:00, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 587M/1.72G [00:23<00:43, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors: 100% 608M/608M [00:23<00:00, 26.0MB/s]\n",
            "Fetching 15 files:  27% 4/15 [00:24<01:13,  6.67s/it]\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 608M/1.72G [00:23<00:30, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 640M/1.72G [00:23<00:21, 51.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 671M/1.72G [00:23<00:14, 71.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 703M/1.72G [00:24<00:10, 94.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 724M/1.72G [00:24<00:09, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 744M/1.72G [00:25<00:26, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 765M/1.72G [00:25<00:20, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 797M/1.72G [00:26<00:13, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 818M/1.72G [00:26<00:11, 78.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 839M/1.72G [00:26<00:15, 58.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 870M/1.72G [00:27<00:13, 63.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 891M/1.72G [00:28<00:21, 38.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 912M/1.72G [00:28<00:17, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  54% 933M/1.72G [00:28<00:13, 59.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 954M/1.72G [00:29<00:16, 46.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 975M/1.72G [00:29<00:16, 45.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 986M/1.72G [00:30<00:15, 46.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 996M/1.72G [00:30<00:18, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 1.01G/1.72G [00:30<00:16, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 1.03G/1.72G [00:30<00:13, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 1.04G/1.72G [00:31<00:12, 55.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 1.05G/1.72G [00:31<00:14, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 1.06G/1.72G [00:31<00:15, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 1.08G/1.72G [00:31<00:12, 50.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 1.10G/1.72G [00:32<00:13, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 1.12G/1.72G [00:32<00:09, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 1.13G/1.72G [00:33<00:11, 49.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 1.14G/1.72G [00:33<00:11, 50.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 1.15G/1.72G [00:33<00:12, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 1.16G/1.72G [00:33<00:12, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 1.17G/1.72G [00:33<00:10, 53.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 1.18G/1.72G [00:34<00:14, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 1.21G/1.72G [00:34<00:11, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 1.22G/1.72G [00:35<00:12, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 1.23G/1.72G [00:35<00:10, 47.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 1.24G/1.72G [00:35<00:10, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  73% 1.25G/1.72G [00:35<00:09, 48.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  73% 1.26G/1.72G [00:35<00:12, 37.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 1.27G/1.72G [00:36<00:10, 41.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 1.29G/1.72G [00:36<00:11, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 1.30G/1.72G [00:37<00:10, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 1.31G/1.72G [00:37<00:10, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 1.32G/1.72G [00:37<00:09, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 1.33G/1.72G [00:37<00:09, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 1.34G/1.72G [00:38<00:11, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 1.35G/1.72G [00:38<00:09, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 1.36G/1.72G [00:38<00:09, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 1.37G/1.72G [00:39<00:10, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 1.38G/1.72G [00:39<00:08, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 1.39G/1.72G [00:39<00:10, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  82% 1.42G/1.72G [00:40<00:08, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  83% 1.43G/1.72G [00:40<00:07, 40.7MB/s]\u001b[A\u001b[A\u001b[A127.0.0.1 - - [05/Oct/2023 14:05:28] \"GET /model HTTP/1.1\" 200 -\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  84% 1.44G/1.72G [00:40<00:06, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  84% 1.45G/1.72G [00:41<00:07, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  85% 1.46G/1.72G [00:41<00:08, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  85% 1.47G/1.72G [00:41<00:07, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  86% 1.48G/1.72G [00:42<00:06, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 1.49G/1.72G [00:42<00:06, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 1.50G/1.72G [00:42<00:07, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 1.51G/1.72G [00:43<00:06, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 1.52G/1.72G [00:43<00:06, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  89% 1.53G/1.72G [00:43<00:05, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  90% 1.55G/1.72G [00:43<00:03, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 1.56G/1.72G [00:44<00:03, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 1.57G/1.72G [00:44<00:04, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  93% 1.59G/1.72G [00:44<00:02, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  93% 1.60G/1.72G [00:45<00:03, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 1.63G/1.72G [00:46<00:04, 21.0MB/s]\u001b[A\u001b[A\u001b[A127.0.0.1 - - [05/Oct/2023 14:05:35] \"GET /model HTTP/1.1\" 200 -\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 1.64G/1.72G [00:47<00:03, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 1.66G/1.72G [00:47<00:01, 37.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  98% 1.69G/1.72G [00:47<00:00, 60.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 1.72G/1.72G [00:47<00:00, 35.9MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:49<00:00,  3.29s/it]\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "127.0.0.1 - - [05/Oct/2023 14:06:12] \"POST /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:06:52] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:06:52.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1266, 1266, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:06:52.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1272, 1272, 3)\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:06:53] \"GET /model_downloaded/lama HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:06:54.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mLoading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\u001b[0m\n",
            "  0% 0/50 [00:00<?, ?it/s]\n",
            "\u001b[32m2023-10-05 14:06:56.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 3882.446050643921ms\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:06:56] \"\u001b[35m\u001b[1mPOST /inpaint HTTP/1.1\u001b[0m\" 500 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:06:57] \"POST /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:08:00.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1266, 1266, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:08:00.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Original\u001b[0m\n",
            "\u001b[32m2023-10-05 14:08:00.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1272, 1272, 3)\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:08:00] \"GET /static/media/coffee-machine-lineal.ee32631219cc3986f861.gif HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:08:02.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 1770.1406478881836ms\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:08:02] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:08:35] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:08:59] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:09:40] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:09:41] \"GET /model_downloaded/cv2 HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:09:42] \"POST /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:10:38.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1266, 1266, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:10:38.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Resize\u001b[0m\n",
            "\u001b[32m2023-10-05 14:10:38.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mRun resize strategy, origin size: (1266, 1266, 3) forward size: (1080, 1080, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:10:38.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1080, 1080, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:10:39.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 406.0542583465576ms\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:10:39] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:11:01] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Oct/2023 14:11:25] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-10-05 14:20:56.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1266, 1266, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:20:56.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Resize\u001b[0m\n",
            "\u001b[32m2023-10-05 14:20:56.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mRun resize strategy, origin size: (1266, 1266, 3) forward size: (1080, 1080, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:20:56.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1080, 1080, 3)\u001b[0m\n",
            "\u001b[32m2023-10-05 14:20:57.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 196.69175148010254ms\u001b[0m\n",
            "127.0.0.1 - - [05/Oct/2023 14:20:57] \"POST /inpaint HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}